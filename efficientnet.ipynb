{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ripeness = ['Green','Midripen','Overripen','Yellowish_Green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "\n",
    "# Define augmentations (same as before)\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=(10,170)),\n",
    "    # transforms.RandomResizedCrop(scale=(0.9, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.3, saturation=0.1),  # Reduced color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "])\n",
    "\n",
    "# Specify source and destination directories\n",
    "source_dir = 'data/Yellowish_Green'  # Replace with your path\n",
    "output_dir = 'augmented_dataset/Yellowish_Green'  # Replace with your output path\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load images and apply augmentations\n",
    "for img_path in glob.glob(os.path.join(source_dir, '*.jpg')):  # Replace '*.jpg' with appropriate extension\n",
    "    img = Image.open(img_path)\n",
    "    for i in range(6):  # Number of augmented images to create per original\n",
    "        augmented_img = augmentations(img)\n",
    "        augmented_img.save(os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(img_path))[0]}_aug_{i}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ripeness = ['Yellowish_Green','Midripen','Overripen','Green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL \n",
    "\n",
    "class BananaRipenessDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, class_name in enumerate(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "        # load augmented images\n",
    "        for label, class_name in enumerate(os.listdir('augmented_dataset')):\n",
    "            class_dir = os.path.join('augmented_dataset', class_name)\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = PIL.Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = BananaRipenessDataset('data', transform=transform)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define dataset sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, 0])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A simple Convolution, Batch Normalization, and Activation Class'''\n",
    "\n",
    "class ConvBnAct(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_out, kernel_size = 3, stride = 1, \n",
    "                 padding = 0, groups = 1, bn = True, act = True,\n",
    "                 bias = False\n",
    "                ):\n",
    "        \n",
    "        super(ConvBnAct, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(n_in, n_out, kernel_size = kernel_size,\n",
    "                              stride = stride, padding = padding,\n",
    "                              groups = groups, bias = bias\n",
    "                             )\n",
    "        self.batch_norm = nn.BatchNorm2d(n_out) if bn else nn.Identity()\n",
    "        self.activation = nn.SiLU() if act else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "''' Squeeze and Excitation Block '''\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, reduced_dim):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(n_in, reduced_dim, kernel_size=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(reduced_dim, n_in, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = self.se(x)\n",
    "        \n",
    "        return x * y\n",
    "                                    \n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "''' Stochastic Depth Module'''\n",
    "\n",
    "class StochasticDepth(nn.Module):\n",
    "    \n",
    "    def __init__(self, survival_prob = 0.8):\n",
    "        super(StochasticDepth, self).__init__()\n",
    "        \n",
    "        self.p =  survival_prob\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if not self.training:\n",
    "            return x\n",
    "        \n",
    "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.p\n",
    "        \n",
    "        return torch.div(x, self.p) * binary_tensor\n",
    "        \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "''' Residual Bottleneck Block with Expansion Factor = N as defined in Mobilenet-V2 paper\n",
    "    with Squeeze and Excitation Block and Stochastic Depth. \n",
    "'''\n",
    "\n",
    "class MBConvN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in, n_out, kernel_size = 3, \n",
    "                 stride = 1, expansion_factor = 6,\n",
    "                 reduction = 4, # Squeeze and Excitation Block\n",
    "                 survival_prob = 0.8 # Stochastic Depth\n",
    "                ):\n",
    "        \n",
    "        super(MBConvN, self).__init__()\n",
    "        \n",
    "        self.skip_connection = (stride == 1 and n_in == n_out) \n",
    "        intermediate_channels = int(n_in * expansion_factor)\n",
    "        padding = (kernel_size - 1)//2\n",
    "        reduced_dim = int(n_in//reduction)\n",
    "        \n",
    "        self.expand = nn.Identity() if (expansion_factor == 1) else ConvBnAct(n_in, intermediate_channels, kernel_size = 1)\n",
    "        self.depthwise_conv = ConvBnAct(intermediate_channels, intermediate_channels,\n",
    "                                        kernel_size = kernel_size, stride = stride, \n",
    "                                        padding = padding, groups = intermediate_channels\n",
    "                                       )\n",
    "        self.se = SqueezeExcitation(intermediate_channels, reduced_dim = reduced_dim)\n",
    "        self.pointwise_conv = ConvBnAct(intermediate_channels, n_out, \n",
    "                                        kernel_size = 1, act = False\n",
    "                                       )\n",
    "        self.drop_layers = StochasticDepth(survival_prob = survival_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        x = self.expand(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.se(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        \n",
    "        if self.skip_connection:\n",
    "            x = self.drop_layers(x)\n",
    "            x += residual\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "'''Efficient-net Class'''\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \n",
    "    '''Generic Efficient net class which takes width multiplier, Depth multiplier, and Survival Prob.'''\n",
    "    \n",
    "    def __init__(self, width_mult = 1, depth_mult = 1, \n",
    "                 dropout_rate = 0.2, num_classes = 1000):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        \n",
    "        last_channel = ceil(1280 * width_mult)\n",
    "        self.features = self._feature_extractor(width_mult, depth_mult, last_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(last_channel, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x.view(x.shape[0], -1))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "        \n",
    "    def _feature_extractor(self, width_mult, depth_mult, last_channel):\n",
    "        \n",
    "        channels = 4*ceil(int(32*width_mult) / 4)\n",
    "        layers = [ConvBnAct(3, channels, kernel_size = 3, stride = 2, padding = 1)]\n",
    "        in_channels = channels\n",
    "        \n",
    "        kernels = [3, 3, 5, 3, 5, 5, 3]\n",
    "        expansions = [1, 6, 6, 6, 6, 6, 6]\n",
    "        num_channels = [16, 24, 40, 80, 112, 192, 320]\n",
    "        num_layers = [1, 2, 2, 3, 3, 4, 1]\n",
    "        strides =[1, 2, 2, 2, 1, 2, 1]\n",
    "        \n",
    "        # Scale channels and num_layers according to width and depth multipliers.\n",
    "        scaled_num_channels = [4*ceil(int(c*width_mult) / 4) for c in num_channels]\n",
    "        scaled_num_layers = [int(d * depth_mult) for d in num_layers]\n",
    "\n",
    "        \n",
    "        for i in range(len(scaled_num_channels)):\n",
    "             \n",
    "            layers += [MBConvN(in_channels if repeat==0 else scaled_num_channels[i], \n",
    "                               scaled_num_channels[i],\n",
    "                               kernel_size = kernels[i],\n",
    "                               stride = strides[i] if repeat==0 else 1, \n",
    "                               expansion_factor = expansions[i]\n",
    "                              )\n",
    "                       for repeat in range(scaled_num_layers[i])\n",
    "                      ]\n",
    "            in_channels = scaled_num_channels[i]\n",
    "        \n",
    "        layers.append(ConvBnAct(in_channels, last_channel, kernel_size = 1, stride = 1, padding = 0))\n",
    "    \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound scaling factors for efficient-net family.\n",
    "efficient_net_config = {\n",
    "    # tuple of width multiplier, depth multiplier, resolution, and Survival Prob\n",
    "    \"b0\" : (1.0, 1.0, 224, 0.2),\n",
    "    \"b1\" : (1.0, 1.1, 240, 0.2),\n",
    "    \"b2\" : (1.1, 1.2, 260, 0.3),\n",
    "    \"b3\" : (1.2, 1.4, 300, 0.3),\n",
    "    \"b4\" : (1.4, 1.8, 380, 0.4),\n",
    "    \"b5\" : (1.6, 2.2, 456, 0.4),\n",
    "    \"b6\" : (1.8, 2.6, 528, 0.5),\n",
    "    \"b7\" : (2.0, 3.1, 600, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    version = 'b0'\n",
    "    width_mult, depth_mult, res, dropout_rate = efficient_net_config[version]\n",
    "    net = EfficientNet(width_mult, depth_mult, dropout_rate)\n",
    "    x = torch.rand(1, 3, res, res)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "#------------------------------------------------------------------------------------------\n",
    "    \n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Performance on test data\n",
    "def calculate_loss_and_accuracy(model, dataloader, size_of_dataset, criterion):\n",
    "    \n",
    "    # Now set model to validation mode.\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    \n",
    "     # Processing the Test Loader\n",
    "    for (inputs, labels) in dataloader:\n",
    "        \n",
    "        # Load data to device.\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Outputs\n",
    "        outputs = model(inputs)\n",
    "        _ , preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Loss and Backpropagation.\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_accuracy += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss/size_of_dataset\n",
    "    epoch_accuracy = running_accuracy/size_of_dataset\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "import copy\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, num_of_epochs):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    track_training_loss = []\n",
    "    track_val_loss = []\n",
    "\n",
    "    for epoch in range(num_of_epochs):\n",
    "\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_of_epochs}')\n",
    "        print('-'*30)\n",
    "\n",
    "        model.train() # Setting model to train.\n",
    "        running_loss = 0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        # Processing the Train Loader\n",
    "        for (inputs, labels) in train_loader:\n",
    "\n",
    "            # Load data to device.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "            # Outputs\n",
    "            outputs = model(inputs)\n",
    "            _ , preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Loss and Backpropagation.\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()*inputs.size(0)\n",
    "            running_accuracy += torch.sum(preds == labels.data)\n",
    "        \n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss/len(train_dataset)\n",
    "        epoch_accuracy = running_accuracy/len(train_dataset)\n",
    "        track_training_loss.append(epoch_loss) # Loss Tracking\n",
    "\n",
    "        print(f'Training Loss: {epoch_loss:.4f} Training Acc.: {epoch_accuracy:.4f}')\n",
    "\n",
    "        # Now set model to validation mode.\n",
    "        model.eval()\n",
    "\n",
    "        val_loss, val_accuracy = calculate_loss_and_accuracy(model, val_loader, len(val_dataset), criterion)\n",
    "        track_val_loss.append(val_loss) # Loss Tracking\n",
    "\n",
    "        if val_accuracy > best_acc:\n",
    "            print(\"Found better model...\")\n",
    "            print('Updating the model weights....\\n')\n",
    "            print(f'Val Loss: {val_loss:.4f} Val Acc.: {val_accuracy:.4f}\\n')\n",
    "\n",
    "            best_acc = val_accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "     \n",
    "    model.load_state_dict(best_model_wts) # update model\n",
    "    \n",
    "    return  model, track_training_loss, track_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # Convert the tensor to a numpy array\n",
    "    img = img / 2 + 0.5  # Unnormalize (if needed)\n",
    "    npimg = img.numpy()  # Convert to numpy\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Transpose to (H, W, C)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get a batch of training data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Create a grid of images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(16):  # Display first 16 images\n",
    "    plt.subplot(4, 4, i + 1)  # 4 rows, 4 columns\n",
    "    imshow(images[i])  # Show the image\n",
    "    plt.title(f'Label: {labels_ripeness[labels[i]]}')  # Show the label\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "------------------------------\n",
      "Training Loss: 1.3819 Training Acc.: 0.2910\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 1.3810 Val Acc.: 0.3006\n",
      "\n",
      "\n",
      "Epoch 2/50\n",
      "------------------------------\n",
      "Training Loss: 1.3423 Training Acc.: 0.3584\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 1.3635 Val Acc.: 0.3481\n",
      "\n",
      "\n",
      "Epoch 3/50\n",
      "------------------------------\n",
      "Training Loss: 1.3040 Training Acc.: 0.4100\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 1.2673 Val Acc.: 0.4715\n",
      "\n",
      "\n",
      "Epoch 4/50\n",
      "------------------------------\n",
      "Training Loss: 1.2012 Training Acc.: 0.5091\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 1.1212 Val Acc.: 0.5158\n",
      "\n",
      "\n",
      "Epoch 5/50\n",
      "------------------------------\n",
      "Training Loss: 0.9900 Training Acc.: 0.5829\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.8237 Val Acc.: 0.5538\n",
      "\n",
      "\n",
      "Epoch 6/50\n",
      "------------------------------\n",
      "Training Loss: 0.7944 Training Acc.: 0.6646\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.6821 Val Acc.: 0.6741\n",
      "\n",
      "\n",
      "Epoch 7/50\n",
      "------------------------------\n",
      "Training Loss: 0.5962 Training Acc.: 0.7851\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.3979 Val Acc.: 0.8608\n",
      "\n",
      "\n",
      "Epoch 8/50\n",
      "------------------------------\n",
      "Training Loss: 0.4600 Training Acc.: 0.8374\n",
      "\n",
      "Epoch 9/50\n",
      "------------------------------\n",
      "Training Loss: 0.3711 Training Acc.: 0.8636\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.2620 Val Acc.: 0.8987\n",
      "\n",
      "\n",
      "Epoch 10/50\n",
      "------------------------------\n",
      "Training Loss: 0.3550 Training Acc.: 0.8612\n",
      "\n",
      "Epoch 11/50\n",
      "------------------------------\n",
      "Training Loss: 0.3253 Training Acc.: 0.8850\n",
      "\n",
      "Epoch 12/50\n",
      "------------------------------\n",
      "Training Loss: 0.3089 Training Acc.: 0.8866\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.2241 Val Acc.: 0.9019\n",
      "\n",
      "\n",
      "Epoch 13/50\n",
      "------------------------------\n",
      "Training Loss: 0.2663 Training Acc.: 0.9025\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.1837 Val Acc.: 0.9241\n",
      "\n",
      "\n",
      "Epoch 14/50\n",
      "------------------------------\n",
      "Training Loss: 0.2494 Training Acc.: 0.9136\n",
      "\n",
      "Epoch 15/50\n",
      "------------------------------\n",
      "Training Loss: 0.2782 Training Acc.: 0.9033\n",
      "\n",
      "Epoch 16/50\n",
      "------------------------------\n",
      "Training Loss: 0.2527 Training Acc.: 0.9064\n",
      "\n",
      "Epoch 17/50\n",
      "------------------------------\n",
      "Training Loss: 0.2334 Training Acc.: 0.9167\n",
      "\n",
      "Epoch 18/50\n",
      "------------------------------\n",
      "Training Loss: 0.1820 Training Acc.: 0.9270\n",
      "\n",
      "Epoch 19/50\n",
      "------------------------------\n",
      "Training Loss: 0.1925 Training Acc.: 0.9207\n",
      "\n",
      "Epoch 20/50\n",
      "------------------------------\n",
      "Training Loss: 0.1972 Training Acc.: 0.9255\n",
      "\n",
      "Epoch 21/50\n",
      "------------------------------\n",
      "Training Loss: 0.1696 Training Acc.: 0.9366\n",
      "\n",
      "Epoch 22/50\n",
      "------------------------------\n",
      "Training Loss: 0.1579 Training Acc.: 0.9405\n",
      "\n",
      "Epoch 23/50\n",
      "------------------------------\n",
      "Training Loss: 0.1602 Training Acc.: 0.9453\n",
      "\n",
      "Epoch 24/50\n",
      "------------------------------\n",
      "Training Loss: 0.1517 Training Acc.: 0.9389\n",
      "\n",
      "Epoch 25/50\n",
      "------------------------------\n",
      "Training Loss: 0.1383 Training Acc.: 0.9556\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.1739 Val Acc.: 0.9335\n",
      "\n",
      "\n",
      "Epoch 26/50\n",
      "------------------------------\n",
      "Training Loss: 0.1183 Training Acc.: 0.9659\n",
      "\n",
      "Epoch 27/50\n",
      "------------------------------\n",
      "Training Loss: 0.1395 Training Acc.: 0.9485\n",
      "\n",
      "Epoch 28/50\n",
      "------------------------------\n",
      "Training Loss: 0.1602 Training Acc.: 0.9318\n",
      "\n",
      "Epoch 29/50\n",
      "------------------------------\n",
      "Training Loss: 0.1628 Training Acc.: 0.9366\n",
      "\n",
      "Epoch 30/50\n",
      "------------------------------\n",
      "Training Loss: 0.1345 Training Acc.: 0.9485\n",
      "\n",
      "Epoch 31/50\n",
      "------------------------------\n",
      "Training Loss: 0.1417 Training Acc.: 0.9469\n",
      "\n",
      "Epoch 32/50\n",
      "------------------------------\n",
      "Training Loss: 0.1365 Training Acc.: 0.9524\n",
      "\n",
      "Epoch 33/50\n",
      "------------------------------\n",
      "Training Loss: 0.1120 Training Acc.: 0.9659\n",
      "\n",
      "Epoch 34/50\n",
      "------------------------------\n",
      "Training Loss: 0.1279 Training Acc.: 0.9540\n",
      "\n",
      "Epoch 35/50\n",
      "------------------------------\n",
      "Training Loss: 0.1139 Training Acc.: 0.9572\n",
      "\n",
      "Epoch 36/50\n",
      "------------------------------\n",
      "Training Loss: 0.1212 Training Acc.: 0.9603\n",
      "\n",
      "Epoch 37/50\n",
      "------------------------------\n",
      "Training Loss: 0.1390 Training Acc.: 0.9477\n",
      "\n",
      "Epoch 38/50\n",
      "------------------------------\n",
      "Training Loss: 0.1187 Training Acc.: 0.9588\n",
      "\n",
      "Epoch 39/50\n",
      "------------------------------\n",
      "Training Loss: 0.1079 Training Acc.: 0.9675\n",
      "\n",
      "Epoch 40/50\n",
      "------------------------------\n",
      "Training Loss: 0.1236 Training Acc.: 0.9588\n",
      "Found better model...\n",
      "Updating the model weights....\n",
      "\n",
      "Val Loss: 0.1646 Val Acc.: 0.9367\n",
      "\n",
      "\n",
      "Epoch 41/50\n",
      "------------------------------\n",
      "Training Loss: 0.1368 Training Acc.: 0.9540\n",
      "\n",
      "Epoch 42/50\n",
      "------------------------------\n",
      "Training Loss: 0.1090 Training Acc.: 0.9643\n",
      "\n",
      "Epoch 43/50\n",
      "------------------------------\n",
      "Training Loss: 0.1244 Training Acc.: 0.9548\n",
      "\n",
      "Epoch 44/50\n",
      "------------------------------\n",
      "Training Loss: 0.1312 Training Acc.: 0.9603\n",
      "\n",
      "Epoch 45/50\n",
      "------------------------------\n",
      "Training Loss: 0.1005 Training Acc.: 0.9675\n",
      "\n",
      "Epoch 46/50\n",
      "------------------------------\n",
      "Training Loss: 0.1377 Training Acc.: 0.9524\n",
      "\n",
      "Epoch 47/50\n",
      "------------------------------\n",
      "Training Loss: 0.1222 Training Acc.: 0.9619\n",
      "\n",
      "Epoch 48/50\n",
      "------------------------------\n",
      "Training Loss: 0.1191 Training Acc.: 0.9643\n",
      "\n",
      "Epoch 49/50\n",
      "------------------------------\n",
      "Training Loss: 0.1143 Training Acc.: 0.9611\n",
      "\n",
      "Epoch 50/50\n",
      "------------------------------\n",
      "Training Loss: 0.1106 Training Acc.: 0.9635\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Standard Resnet-18 Model.\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize Efficientnet model\n",
    "NUM_OF_CLASSES = len(labels_ripeness)\n",
    "version = 'b0'\n",
    "width_mult, depth_mult, res, dropout_rate = efficient_net_config[version]\n",
    "model = EfficientNet(width_mult, depth_mult, dropout_rate, num_classes = NUM_OF_CLASSES)\n",
    "model = model.to(device) # Load model to device.\n",
    "\n",
    "\n",
    "# Criterion.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "NUM_OF_EPOCHS = 50\n",
    "\n",
    "# Training\n",
    "best_model, track_training_loss, track_val_loss  = train(model = model,\n",
    "                   criterion = criterion,\n",
    "                   optimizer = optimizer,\n",
    "                   scheduler = exp_lr_scheduler,\n",
    "                   num_of_epochs = NUM_OF_EPOCHS\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualize the training and validation loss\n",
    "plt.plot(track_training_loss, label='Training Loss')\n",
    "plt.plot(track_val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(best_model.state_dict(), 'efficient_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# load images and predict\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "original_img = Image.open('test/1.png').convert(\"RGB\")\n",
    "img = transform(original_img).unsqueeze(0).to(device)\n",
    "\n",
    "# Predict the class\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = best_model(img)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    print(pred)\n",
    "\n",
    "# Display the image and the prediction\n",
    "plt.imshow(original_img)\n",
    "plt.title(labels_ripeness[pred.item()])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
